import streamlit as st
import torch
import whisper
import torchaudio
import os
import numpy as np
from pydub import AudioSegment
from pathlib import Path

# âœ… ConfiguraÃ§Ã£o inicial do Streamlit
st.set_page_config(page_title="ğŸ™ï¸ TranscriÃ§Ã£o de Ãudio", layout="centered")

st.title("ğŸ™ï¸ TranscriÃ§Ã£o de Ãudio com IA")
st.write("FaÃ§a upload de um arquivo de Ã¡udio para transcriÃ§Ã£o! (Formatos suportados: WAV, MP3, M4A)")

# ğŸ”¹ Escolha do modelo Whisper
model_size = st.selectbox("Selecione o modelo Whisper:", ["tiny", "base", "small", "medium", "large"])

# ğŸ”¹ Escolha do idioma
language = st.selectbox("Escolha o idioma:", ["PortuguÃªs", "InglÃªs", "Espanhol"])
lang_code = {"PortuguÃªs": "pt", "InglÃªs": "en", "Espanhol": "es"}[language]

# ğŸ”¹ OpÃ§Ã£o de GPU (se disponÃ­vel)
use_gpu = st.checkbox("Usar GPU (se disponÃ­vel)", value=torch.cuda.is_available())

# ğŸ”¹ Upload do arquivo de Ã¡udio (suporta MP3, M4A, WAV)
uploaded_file = st.file_uploader("FaÃ§a upload do arquivo de Ã¡udio", type=["wav", "mp3", "m4a"])


def load_audio(input_audio, format):
    """
    Carrega o Ã¡udio de entrada sem conversÃ£o.
    Utiliza torchaudio para WAV e pydub para MP3 e M4A.
    Retorna o waveform (Tensor) e a taxa de amostragem.
    """
    if format == "wav":
        waveform, sample_rate = torchaudio.load(input_audio)
    else:
        audio = AudioSegment.from_file(input_audio, format=format)
        sample_rate = audio.frame_rate
        samples = np.array(audio.get_array_of_samples()).astype(np.float32)
        waveform = torch.tensor(samples).unsqueeze(0) / 32768.0  # Normalizar

    return waveform, sample_rate


if uploaded_file is not None:
    st.audio(uploaded_file, format="audio/wav")

    if st.button("ğŸ” Transcrever"):
        with st.spinner("â³ Transcrevendo... Aguarde..."):
            # âœ… Salvar o arquivo temporariamente
            temp_audio_path = Path(f"temp_audio.{uploaded_file.name.split('.')[-1]}")
            with open(temp_audio_path, "wb") as f:
                f.write(uploaded_file.read())

            # âœ… Carregar o Ã¡udio diretamente sem conversÃ£o
            file_format = temp_audio_path.suffix[1:]  # Pega extensÃ£o sem o ponto
            waveform, sample_rate = load_audio(str(temp_audio_path), file_format)

            # âœ… Carregar o modelo Whisper
            device = "cuda" if use_gpu and torch.cuda.is_available() else "cpu"
            model = whisper.load_model(model_size, device=device)

            # âœ… TranscriÃ§Ã£o do Ã¡udio
            result = model.transcribe(str(temp_audio_path), language=lang_code)

            # âœ… Exibir transcriÃ§Ã£o
            st.subheader("ğŸ“œ TranscriÃ§Ã£o:")
            st.text_area("Resultado:", result["text"], height=300)

            # ğŸ”¥ Salvar a transcriÃ§Ã£o
            output_file = Path("transcription.txt")
            with open(output_file, "w", encoding="utf-8") as f:
                f.write(result["text"])

            st.success("âœ… TranscriÃ§Ã£o concluÃ­da e salva!")

            # ğŸ”¥ BotÃ£o para baixar a transcriÃ§Ã£o
            with open(output_file, "rb") as f:
                st.download_button("â¬‡ï¸ Baixar TranscriÃ§Ã£o", f, file_name="transcription.txt", mime="text/plain")

            # ğŸ—‘ï¸ Remover arquivos temporÃ¡rios
            os.remove(temp_audio_path)
